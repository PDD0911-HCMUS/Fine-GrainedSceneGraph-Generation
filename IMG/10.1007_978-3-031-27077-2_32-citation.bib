@InProceedings{10.1007/978-3-031-27077-2_32,
author="Pham, Dinh-Duy
and Dao, Minh-Son
and Nguyen, Thanh-Binh",
editor="Dang-Nguyen, Duc-Tien
and Gurrin, Cathal
and Larson, Martha
and Smeaton, Alan F.
and Rudinac, Stevan
and Dao, Minh-Son
and Trattner, Christoph
and Chen, Phoebe",
title="A Cross-modal Attention Model for Fine-Grained Incident Retrieval from Dashcam Videos",
booktitle="MultiMedia Modeling",
year="2023",
publisher="Springer International Publishing",
address="Cham",
pages="409--420",
abstract="Dashcam video has become popular recently due to the safety of both individuals and communities. While individuals can have undeniable evidence for legal and insurance, communities can benefit from sharing these dashcam videos for further traffic education and criminal investigation. Moreover, relying on recent computer vision and AI development, a few companies have launched the so-called AI dashcam that can alert drivers to near-risk accidents (e.g., following distance detection, forward collision warning) to improve driver safety. Unfortunately, even though dashcam videos create a driver's travel log (i.e., a traveling diary), little research focuses on creating a valuable and friendly tool to find any incident or event with few described sketches by users. Inspired by these observations, we introduce an interactive incident detection and retrieval system for first-view travel-log data that can retrieve fine-grained incidents for both defined and undefined incidents. Moreover, the system gives promising results when evaluated on several public datasets and popular text-image retrieval methods. The source code is published at https://github.com/PDD0911-HCMUS/Cross{\_}Model{\_}Attention",
isbn="978-3-031-27077-2"
}

